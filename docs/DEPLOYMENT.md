# üöÄ Guia de Deploy do Video AI Editor

<div align="center">
  <img src="https://github.com/LuwiEditor-AI/LuwiEditor-AI-Code/raw/main/assets/deploy-logo.png" alt="Deploy Logo" width="200">
  
  [![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
  [![Kubernetes](https://img.shields.io/badge/Kubernetes-Supported-green.svg)](https://kubernetes.io/)
  [![Vercel](https://img.shields.io/badge/Vercel-Deployed-black.svg)](https://vercel.com/)
  [![AWS](https://img.shields.io/badge/AWS-Cloud-orange.svg)](https://aws.amazon.com/)
</div>

## üìã √çndice

- [Vis√£o Geral](#vis√£o-geral)
- [Pr√©-requisitos](#pr√©-requisitos)
- [Vari√°veis de Ambiente](#vari√°veis-de-ambiente)
- [Deploy Local](#deploy-local)
- [Deploy com Docker](#deploy-com-docker)
- [Deploy na Vercel](#deploy-na-vercel)
- [Deploy em Produ√ß√£o](#deploy-em-produ√ß√£o)
- [Monitoramento](#monitoramento)
- [Troubleshooting](#troubleshooting)

## üåê Vis√£o Geral

Este guia cobre diferentes estrat√©gias de deploy para o Video AI Editor, desde desenvolvimento local at√© produ√ß√£o em escala. A aplica√ß√£o √© composta por:

- **Frontend**: Aplica√ß√£o React com PWA
- **Backend**: API Django com microsservi√ßos Flask
- **AI Services**: Servi√ßos de processamento de IA
- **Banco de Dados**: PostgreSQL
- **Cache**: Redis
- **Armazenamento**: AWS S3 ou similar

### Arquitetura de Deploy

```mermaid
graph TB
    A[Usu√°rio] --> B[CDN/Load Balancer]
    B --> C[Frontend Vercel]
    B --> D[API Gateway]
    D --> E[Backend Kubernetes]
    E --> F[PostgreSQL]
    E --> G[Redis]
    E --> H[AI Services]
    H --> I[GPU Nodes]
    E --> J[File Storage]
```

## ‚úÖ Pr√©-requisitos

### Sistema Operacional
- **Linux**: Ubuntu 20.04+ ou CentOS 8+
- **macOS**: 11.0+ (Big Sur)
- **Windows**: 10+ com WSL2

### Software Necess√°rio

| Ferramenta | Vers√£o M√≠nima | Instala√ß√£o |
|------------|----------------|------------|
| **Node.js** | 18.x | [nvm](https://github.com/nvm-sh/nvm) ou [site oficial](https://nodejs.org/) |
| **Python** | 3.11+ | [pyenv](https://github.com/pyenv/pyenv) ou [site oficial](https://www.python.org/) |
| **Docker** | 20.10+ | [Docker Desktop](https://www.docker.com/products/docker-desktop) |
| **Git** | 2.30+ | [Git SCM](https://git-scm.com/) |
| **PostgreSQL** | 13+ | [PostgreSQL.org](https://www.postgresql.org/download/) |
| **Redis** | 6.0+ | [Redis.io](https://redis.io/download) |

### Hardware Recomendado

| Ambiente | CPU | RAM | Armazenamento | GPU |
|----------|-----|-----|---------------|-----|
| **Desenvolvimento** | 4 cores | 8GB | 50GB SSD | Opcional |
| **Staging** | 8 cores | 16GB | 100GB SSD | Recomendado |
| **Produ√ß√£o** | 16+ cores | 32GB+ | 500GB+ SSD | Obrigat√≥rio |

## üîß Vari√°veis de Ambiente

### Frontend (.env)

```bash
# Configura√ß√µes da API
REACT_APP_API_URL=https://api.video-ai-editor.com
REACT_APP_WS_URL=wss://api.video-ai-editor.com/ws

# Configura√ß√µes de Autentica√ß√£o
REACT_APP_SUPABASE_URL=https://your-project.supabase.co
REACT_APP_SUPABASE_ANON_KEY=your-anon-key

# Configura√ß√µes de Features
REACT_APP_ENABLE_AI_FEATURES=true
REACT_APP_ENABLE_ANALYTICS=false

# Configura√ß√µes de Deploy
GENERATE_SOURCEMAP=false
INLINE_RUNTIME_CHUNK=false
```

### Backend (.env)

```bash
# Configura√ß√µes do Django
DEBUG=false
SECRET_KEY=your-super-secret-key-here
ALLOWED_HOSTS=api.video-ai-editor.com,localhost,127.0.0.1

# Configura√ß√µes do Banco de Dados
DATABASE_URL=postgresql://username:password@localhost:5432/video_ai_editor
DB_NAME=video_ai_editor
DB_USER=username
DB_PASSWORD=password
DB_HOST=localhost
DB_PORT=5432

# Configura√ß√µes do Redis
REDIS_URL=redis://localhost:6379/0
CACHE_TTL=3600

# Configura√ß√µes de IA
HUGGINGFACE_API_KEY=your-huggingface-key
OPENAI_API_KEY=your-openai-key
AI_MODEL_PATH=/app/models

# Configura√ß√µes de Armazenamento
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_STORAGE_BUCKET_NAME=video-ai-editor-storage
AWS_S3_REGION=us-east-1

# Configura√ß√µes de Seguran√ßa
CORS_ALLOWED_ORIGINS=https://video-ai-editor.com,https://app.video-ai-editor.com
SECURE_SSL_REDIRECT=true
SECURE_HSTS_SECONDS=31536000

# Configura√ß√µes de Email
EMAIL_HOST=smtp.gmail.com
EMAIL_PORT=587
EMAIL_HOST_USER=your-email@gmail.com
EMAIL_HOST_PASSWORD=your-app-password
DEFAULT_FROM_EMAIL=noreply@video-ai-editor.com

# Configura√ß√µes de Monitoramento
SENTRY_DSN=your-sentry-dsn
LOG_LEVEL=INFO
```

### Docker Compose (.env)

```bash
# Configura√ß√µes do Projeto
COMPOSE_PROJECT_NAME=video-ai-editor
COMPOSE_FILE=docker-compose.yml:docker-compose.prod.yml

# Vers√µes das Imagens
NODE_VERSION=18-alpine
PYTHON_VERSION=3.11-slim
POSTGRES_VERSION=15-alpine
REDIS_VERSION=7-alpine

# Configura√ß√µes de Rede
NETWORK_NAME=video-ai-editor-network
```

## üè† Deploy Local

### 1. Clone o Reposit√≥rio

```bash
git clone https://github.com/video-ai-editor/video-ai-editor.git
cd video-ai-editor
```

### 2. Configure o Ambiente

```bash
# Copie arquivos de exemplo
cp frontend/.env.example frontend/.env
cp backend/.env.example backend/.env

# Edite os arquivos com suas configura√ß√µes
nano frontend/.env
nano backend/.env
```

### 3. Instale Depend√™ncias do Backend

```bash
cd backend

# Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/macOS
# ou
venv\Scripts\activate     # Windows

# Instale depend√™ncias
pip install -r requirements.txt

# Aplique migra√ß√µes
python manage.py migrate

# Crie superusu√°rio
python manage.py createsuperuser
```

### 4. Instale Depend√™ncias do Frontend

```bash
cd ../frontend

# Instale depend√™ncias
npm install

# Construa para produ√ß√£o
npm run build
```

### 5. Inicie os Servi√ßos

```bash
# Terminal 1 - Backend
cd backend
python manage.py runserver 0.0.0.0:8000

# Terminal 2 - Frontend (desenvolvimento)
cd frontend
npm start

# Terminal 3 - Worker (opcional)
cd backend
celery -A backend worker -l info
```

### 6. Acesse a Aplica√ß√£o

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **Admin**: http://localhost:8000/admin

## üê≥ Deploy com Docker

### 1. Dockerfile do Frontend

```dockerfile
# frontend/Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

# Copie package files
COPY package*.json ./

# Instale depend√™ncias
RUN npm ci --only=production

# Copie c√≥digo fonte
COPY . .

# Construa aplica√ß√£o
RUN npm run build

# Imagem de produ√ß√£o
FROM nginx:alpine

# Copie build para nginx
COPY --from=builder /app/build /usr/share/nginx/html

# Copie configura√ß√£o do nginx
COPY nginx.conf /etc/nginx/nginx.conf

# Exponha porta
EXPOSE 80

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost/ || exit 1

CMD ["nginx", "-g", "daemon off;"]
```

### 2. Dockerfile do Backend

```dockerfile
# backend/Dockerfile
FROM python:3.11-slim

# Configure ambiente
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# Instale depend√™ncias do sistema
RUN apt-get update \
    && apt-get install -y --no-install-recommends \
        postgresql-client \
        build-essential \
        libpq-dev \
        ffmpeg \
        libsm6 \
        libxext6 \
        libxrender-dev \
        libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*

# Crie diret√≥rio da aplica√ß√£o
WORKDIR /app

# Copie requirements
COPY requirements.txt .

# Instale depend√™ncias Python
RUN pip install --no-cache-dir -r requirements.txt

# Copie c√≥digo
COPY . .

# Crie usu√°rio n√£o-root
RUN adduser --disabled-password --gecos '' appuser
RUN chown -R appuser:appuser /app
USER appuser

# Exponha porta
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health/ || exit 1

# Comando de inicializa√ß√£o
CMD ["gunicorn", "--bind", "0.0.0.0:8000", "backend.wsgi:application"]
```

### 3. Docker Compose

```yaml
# docker-compose.yml
version: '3.8'

services:
  # Banco de Dados
  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: video_ai_editor
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Cache
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  # Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@db:5432/video_ai_editor
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./backend:/app
      - media_files:/app/media
      - static_files:/app/static
    ports:
      - "8000:8000"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Worker
  worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    command: celery -A backend worker -l info
    environment:
      - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@db:5432/video_ai_editor
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./backend:/app
      - media_files:/app/media
    depends_on:
      - db
      - redis
      - backend

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    depends_on:
      - backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 30s
      timeout: 3s
      retries: 3

volumes:
  postgres_data:
  redis_data:
  media_files:
  static_files:

networks:
  default:
    name: video-ai-editor-network
```

### 4. Docker Compose de Produ√ß√£o

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - static_files:/var/www/static
      - media_files:/var/www/media
    depends_on:
      - frontend
      - backend
    restart: unless-stopped

  # Backend (modificado para produ√ß√£o)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    environment:
      - DEBUG=false
      - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@db:5432/video_ai_editor
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - media_files:/app/media
      - static_files:/app/static
    restart: unless-stopped
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Worker com suporte a GPU
  worker:
    build:
      context: ./backend
      dockerfile: Dockerfile.gpu
    environment:
      - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@db:5432/video_ai_editor
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - media_files:/app/media
      - ./models:/app/models
    deploy:
      replicas: 2
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
```

### 5. Comandos de Deploy

```bash
# Construa imagens
docker-compose build

# Inicie servi√ßos
docker-compose up -d

# Verifique logs
docker-compose logs -f

# Escale servi√ßos
docker-compose up -d --scale backend=3 --scale worker=2

# Atualize servi√ßos
docker-compose pull
docker-compose up -d
```

## üåê Deploy na Vercel

### 1. Configure o Projeto

```bash
# Instale Vercel CLI
npm i -g vercel

# Fa√ßa login
vercel login

# Configure projeto
cd frontend
vercel
```

### 2. vercel.json

```json
{
  "version": 2,
  "name": "luwieditorai",
  "builds": [
    {
      "src": "package.json",
      "use": "@vercel/static-build",
      "config": {
        "distDir": "build"
      }
    }
  ],
  "routes": [
    {
      "src": "/(.*)",
      "dest": "/index.html"
    }
  ],
  "env": {
    "REACT_APP_API_URL": "@api_url",
    "REACT_APP_WS_URL": "@ws_url",
    "REACT_APP_SUPABASE_URL": "@supabase_url",
    "REACT_APP_SUPABASE_ANON_KEY": "@supabase_anon_key"
  },
  "build": {
    "env": {
      "GENERATE_SOURCEMAP": "false"
    }
  },
  "functions": {},
  "regions": ["iad1"],
  "framework": "create-react-app"
}
```

### 3. Deploy Autom√°tico

```bash
# Deploy para produ√ß√£o
vercel --prod

# Deploy para preview
vercel

# Alias personalizado
vercel --prod --alias video-ai-editor.vercel.app
```

### 4. Integra√ß√£o com GitHub

1. Conecte reposit√≥rio ao Vercel
2. Configure vari√°veis de ambiente
3. Configure dom√≠nio personalizado
4. Habilite deploy autom√°tico

## üè≠ Deploy em Produ√ß√£o

### 1. Kubernetes - Namespace

```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: video-ai-editor
  labels:
    name: video-ai-editor
```

### 2. Kubernetes - ConfigMap

```yaml
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: video-ai-editor-config
  namespace: video-ai-editor
data:
  API_URL: "https://api.video-ai-editor.com"
  WS_URL: "wss://api.video-ai-editor.com/ws"
  LOG_LEVEL: "INFO"
  REDIS_URL: "redis://redis-service:6379/0"
```

### 3. Kubernetes - Secret

```yaml
# k8s/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: video-ai-editor-secrets
  namespace: video-ai-editor
type: Opaque
data:
  DATABASE_URL: <base64-encoded-database-url>
  SECRET_KEY: <base64-encoded-secret-key>
  AWS_ACCESS_KEY_ID: <base64-encoded-aws-key>
  AWS_SECRET_ACCESS_KEY: <base64-encoded-aws-secret>
```

### 4. Kubernetes - Backend Deployment

```yaml
# k8s/backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend-deployment
  namespace: video-ai-editor
spec:
  replicas: 3
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
      - name: backend
        image: video-ai-editor/backend:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: video-ai-editor-secrets
              key: DATABASE_URL
        - name: SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: video-ai-editor-secrets
              key: SECRET_KEY
        envFrom:
        - configMapRef:
            name: video-ai-editor-config
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health/
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health/
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
```

### 5. Kubernetes - Service

```yaml
# k8s/backend-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: backend-service
  namespace: video-ai-editor
spec:
  selector:
    app: backend
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: ClusterIP
```

### 6. Kubernetes - Ingress

```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: video-ai-editor-ingress
  namespace: video-ai-editor
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "100m"
spec:
  tls:
  - hosts:
    - video-ai-editor.com
    - api.video-ai-editor.com
    secretName: video-ai-editor-tls
  rules:
  - host: video-ai-editor.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend-service
            port:
              number: 80
  - host: api.video-ai-editor.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: backend-service
            port:
              number: 80
```

### 7. Scripts de Deploy

```bash
#!/bin/bash
# scripts/deploy.sh

set -e

echo "üöÄ Iniciando deploy do Video AI Editor..."

# Vari√°veis
NAMESPACE="video-ai-editor"
DOCKER_REGISTRY="your-registry.com"
VERSION=${1:-latest}

# Build e push das imagens
echo "üì¶ Build das imagens Docker..."
docker build -t $DOCKER_REGISTRY/backend:$VERSION ./backend
docker build -t $DOCKER_REGISTRY/frontend:$VERSION ./frontend

echo "üì§ Push das imagens..."
docker push $DOCKER_REGISTRY/backend:$VERSION
docker push $DOCKER_REGISTRY/frontend:$VERSION

# Aplica configura√ß√µes Kubernetes
echo "‚ò∏Ô∏è Aplicando configura√ß√µes Kubernetes..."
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/secret.yaml
kubectl apply -f k8s/backend-deployment.yaml
kubectl apply -f k8s/backend-service.yaml
kubectl apply -f k8s/frontend-deployment.yaml
kubectl apply -f k8s/frontend-service.yaml
kubectl apply -f k8s/ingress.yaml

# Aguarda deploy
echo "‚è≥ Aguardando deploy..."
kubectl rollout status deployment/backend-deployment -n $NAMESPACE
kubectl rollout status deployment/frontend-deployment -n $NAMESPACE

# Verifica√ß√£o
echo "‚úÖ Deploy conclu√≠do com sucesso!"
echo "üåê Frontend: https://luwieditorai.xyz"
echo "üîå API: https://api.luwieditorai.xyz/v1"
```

## üìä Monitoramento

### 1. Prometheus - Configura√ß√£o

```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

scrape_configs:
  - job_name: 'video-ai-editor-backend'
    static_configs:
      - targets: ['backend-service:80']
    metrics_path: /metrics
    scrape_interval: 30s

  - job_name: 'video-ai-editor-frontend'
    static_configs:
      - targets: ['frontend-service:80']
    metrics_path: /metrics
    scrape_interval: 30s

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

### 2. Grafana - Dashboard

```json
{
  "dashboard": {
    "title": "Video AI Editor Monitoring",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "singlestat",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])",
            "legendFormat": "Error Rate"
          }
        ]
      }
    ]
  }
}
```

### 3. Health Checks

```python
# backend/health_checks.py
from django.http import JsonResponse
from django.db import connection
from django.core.cache import cache
import redis
import psutil

def health_check(request):
    """Health check completo"""
    checks = {
        'database': check_database(),
        'cache': check_cache(),
        'redis': check_redis(),
        'disk_space': check_disk_space(),
        'memory': check_memory()
    }
    
    all_healthy = all(check['status'] == 'healthy' for check in checks.values())
    
    status_code = 200 if all_healthy else 503
    
    return JsonResponse({
        'status': 'healthy' if all_healthy else 'unhealthy',
        'checks': checks,
        'timestamp': timezone.now().isoformat()
    }, status=status_code)

def check_database():
    """Verifica conex√£o com banco de dados"""
    try:
        with connection.cursor() as cursor:
            cursor.execute("SELECT 1")
        return {'status': 'healthy', 'message': 'Database connection OK'}
    except Exception as e:
        return {'status': 'unhealthy', 'message': str(e)}

def check_cache():
    """Verifica cache"""
    try:
        cache.set('health_check', 'ok', 10)
        cache.get('health_check')
        return {'status': 'healthy', 'message': 'Cache OK'}
    except Exception as e:
        return {'status': 'unhealthy', 'message': str(e)}

def check_redis():
    """Verifica Redis"""
    try:
        r = redis.Redis(host='redis', port=6379, db=0)
        r.ping()
        return {'status': 'healthy', 'message': 'Redis OK'}
    except Exception as e:
        return {'status': 'unhealthy', 'message': str(e)}

def check_disk_space():
    """Verifica espa√ßo em disco"""
    disk_usage = psutil.disk_usage('/')
    free_percent = (disk_usage.free / disk_usage.total) * 100
    
    if free_percent < 10:
        return {'status': 'unhealthy', 'message': f'Low disk space: {free_percent:.1f}%'}
    
    return {'status': 'healthy', 'message': f'Disk space OK: {free_percent:.1f}% free'}

def check_memory():
    """Verifica uso de mem√≥ria"""
    memory = psutil.virtual_memory()
    used_percent = memory.percent
    
    if used_percent > 90:
        return {'status': 'unhealthy', 'message': f'High memory usage: {used_percent:.1f}%'}
    
    return {'status': 'healthy', 'message': f'Memory OK: {used_percent:.1f}% used'}
```

## üîß Troubleshooting

### Problemas Comuns

#### 1. Frontend N√£o Carrega

**Sintomas:**
- P√°gina em branco
- Erro 404
- Recursos n√£o encontrados

**Solu√ß√µes:**
```bash
# Verifique build
cd frontend
npm run build

# Verifique configura√ß√£o do nginx
cat nginx.conf

# Verifique logs
docker-compose logs frontend
```

#### 2. Backend N√£o Responde

**Sintomas:**
- Timeout na API
- Erro 502 Bad Gateway
- Servi√ßo n√£o inicia

**Solu√ß√µes:**
```bash
# Verifique vari√°veis de ambiente
docker-compose exec backend env | grep DATABASE_URL

# Verifique conex√£o com banco
docker-compose exec backend python manage.py dbshell

# Verifique logs
docker-compose logs backend
```

#### 3. IA Services N√£o Funcionam

**Sintomas:**
- Tarefas de IA falham
- Erro de GPU n√£o encontrada
- Processamento lento

**Solu√ß√µes:**
```bash
# Verifique drivers NVIDIA
nvidia-smi

# Verifique Docker com GPU
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi

# Verifique logs do worker
docker-compose logs worker
```

#### 4. Problemas de Performance

**Sintomas:**
- Respostas lentas
- Alto uso de CPU
- Memory leaks

**Solu√ß√µes:**
```bash
# Monitore recursos
docker stats

# Verifique queries lentas
docker-compose exec db psql -U postgres -d video_ai_editor -c "
SELECT query, mean_time, calls 
FROM pg_stat_statements 
ORDER BY mean_time DESC 
LIMIT 10;"

# Perfil de c√≥digo
docker-compose exec backend python -m cProfile -o profile.stats manage.py runserver
```

### Scripts de Diagn√≥stico

```bash
#!/bin/bash
# scripts/diagnose.sh

echo "üîç Diagn√≥stico do Video AI Editor..."

# Verifica containers
echo "üì¶ Status dos containers:"
docker-compose ps

# Verifica recursos
echo "üíª Uso de recursos:"
docker stats --no-stream

# Verifica logs de erro
echo "üìù Logs de erro recentes:"
docker-compose logs --tail=50 | grep -i error

# Verifica conectividade
echo "üåê Teste de conectividade:"
curl -f http://localhost:8000/health/ || echo "Backend n√£o responde"
curl -f http://localhost:3000 || echo "Frontend n√£o responde"

# Verifica banco de dados
echo "üóÑÔ∏è Status do banco de dados:"
docker-compose exec db pg_isready -U postgres

# Verifica Redis
echo "üî¥ Status do Redis:"
docker-compose exec redis redis-cli ping

echo "‚úÖ Diagn√≥stico conclu√≠do!"
```

### Backup e Restore

```bash
#!/bin/bash
# scripts/backup.sh

BACKUP_DIR="/backups/video-ai-editor"
DATE=$(date +%Y%m%d_%H%M%S)

# Criar diret√≥rio de backup
mkdir -p $BACKUP_DIR

# Backup do banco de dados
echo "üì¶ Fazendo backup do banco de dados..."
docker-compose exec db pg_dump -U postgres video_ai_editor > $BACKUP_DIR/db_backup_$DATE.sql

# Backup dos volumes
echo "üì¶ Fazendo backup dos volumes..."
docker run --rm -v video-ai-editor_media_files:/data -v $BACKUP_DIR:/backup alpine tar czf /backup/media_backup_$DATE.tar.gz -C /data .
docker run --rm -v video-ai-editor_static_files:/data -v $BACKUP_DIR:/backup alpine tar czf /backup/static_backup_$DATE.tar.gz -C /data .

# Limpeza de backups antigos
echo "üßπ Limpando backups antigos..."
find $BACKUP_DIR -name "*.sql" -mtime +7 -delete
find $BACKUP_DIR -name "*.tar.gz" -mtime +7 -delete

echo "‚úÖ Backup conclu√≠do: $BACKUP_DIR"
```

### Checklist de Deploy

```markdown
## ‚úÖ Pr√©-Deploy
- [ ] Backup do banco de dados
- [ ] Testes em ambiente de staging
- [ ] Verifica√ß√£o de vari√°veis de ambiente
- [ ] Build das imagens Docker
- [ ] Verifica√ß√£o de recursos dispon√≠veis

## ‚úÖ Durante o Deploy
- [ ] Monitoramento dos logs
- [ ] Verifica√ß√£o de health checks
- [ ] Teste de funcionalidades cr√≠ticas
- [ ] Monitoramento de performance

## ‚úÖ P√≥s-Deploy
- [ ] Verifica√ß√£o completa da aplica√ß√£o
- [ ] Monitoramento por 24 horas
- [ ] Documenta√ß√£o de mudan√ßas
- [ ] Comunicado aos usu√°rios (se necess√°rio)

```
**Commit Message:**

docs(deploy): add comprehensive deployment guide for multiple environments

- Add deployment instructions for local, Docker, Vercel, and Kubernetes
- Include detailed environment variable configuration
- Add Docker and Docker Compose configurations for production
- Include Kubernetes manifests with ingress, services, and deployments
- Add monitoring setup with Prometheus and Grafana
- Include troubleshooting guide and diagnostic scripts
- Add backup and restore procedures

This guide enables teams to deploy the Video AI Editor
reliably across different infrastructure setups.
```
